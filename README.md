<div align="center">

# ğŸ§  Mnemora

### Local-First Personal Context Engine

**Chat with your files using AI â€” completely offline, 100% private.**

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![Electron](https://img.shields.io/badge/Electron-28-47848F?logo=electron)](https://www.electronjs.org/)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python&logoColor=white)](https://python.org)
[![React](https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=black)](https://reactjs.org)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20AI-000000)](https://ollama.ai)

[Features](#-features) â€¢ [Screenshots](#-screenshots) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Contributing](#-contributing) â€¢ [License](#-license)

</div>

---

## ğŸ¯ What is Mnemora?

Mnemora is a **desktop application** that lets you have natural conversations with your local documents â€” PDFs, Markdown notes, code files, and more. Powered entirely by **local AI models** through Ollama, your data never leaves your computer.

### Why Mnemora?

| Feature | Description |
|---------|-------------|
| ğŸ”’ **100% Private** | All processing happens locally. No cloud, no data sharing, no subscriptions |
| âš¡ **Semantic Search** | Find information across thousands of documents using natural language |
| ğŸ“š **Source Citations** | Every answer shows exactly which files it came from with relevance scores |
| ğŸ¨ **Beautiful UI** | Modern, dark-themed interface built with React and Tailwind CSS |
| ğŸ§© **Extensible** | Open source, well-documented, and easy to customize |

---

## âœ¨ Features

### Core Capabilities

- **ğŸ“ Index Any Folder** â€” Add folders containing your documents and let Mnemora understand them
- **ğŸ’¬ Natural Chat Interface** â€” Ask questions in plain English and get intelligent answers
- **ğŸ”— Smart Citations** â€” See exactly which documents contributed to each answer
- **ğŸ“Š Relevance Scoring** â€” Visual indicators show how relevant each source is
- **âš¡ Streaming Responses** â€” See AI responses as they're generated in real-time

### Document Support

| Type | Extensions | Features |
|------|------------|----------|
| **Markdown** | `.md`, `.markdown` | Obsidian [[wiki-links]], #tags, YAML frontmatter |
| **PDF** | `.pdf` | Full text extraction with page markers |
| **Plain Text** | `.txt` | Direct content indexing |
| **Code** | `.py`, `.js`, `.ts`, `.go`, `.rs`, etc. | Language detection, structure extraction |

### Powered By

- **[Ollama](https://ollama.ai)** â€” Local LLM inference with models like Llama 3.2, Mistral, CodeLlama
- **[ChromaDB](https://trychroma.com)** â€” High-performance vector database for semantic search
- **[FastAPI](https://fastapi.tiangolo.com)** â€” Modern Python backend with async support
- **[Electron](https://electronjs.org)** â€” Cross-platform desktop application
- **[React](https://reactjs.org)** â€” Component-based UI with Zustand for state management

---

## ğŸ“¸ Screenshots

<div align="center">

### Chat Interface
Ask natural language questions about your documents.

![Chat Interface](docs/screenshots/chat-interface.png)

### Document Understanding
Get detailed answers with information extracted from your files.

![Document Query](docs/screenshots/document-query.png)

### Source Citations
See exactly which files contributed to each answer with relevance scores.

![Sources Panel](docs/screenshots/sources-panel.png)

</div>

---

## ğŸš€ Installation

### Prerequisites

| Requirement | Version | Download |
|-------------|---------|----------|
| Node.js | 18+ | [nodejs.org](https://nodejs.org/) |
| Python | 3.10+ | [python.org](https://python.org/) |
| Ollama | Latest | [ollama.ai](https://ollama.ai/download) |

### Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/AIkaptan/Mnemora.git
cd Mnemora

# 2. Install Node.js dependencies
npm install

# 3. Install Python dependencies
cd backend
pip install -r requirements.txt
cd ..
```

### First Run

Mnemora includes **automatic setup** â€” on first launch, it will:

1. âœ… Check if Ollama is installed and running
2. âœ… Guide you to install Ollama if needed  
3. âœ… Download required AI models automatically
4. âœ… Start the application once ready

---

## ğŸ“– Usage

### Running the Application

You need **3 terminals** running:

```bash
# Terminal 1: Start Ollama
ollama serve

# Terminal 2: Start Python backend
cd backend
python main.py

# Terminal 3: Start the Electron app
npm run electron
```

### Adding Documents

1. Click the **â•** button next to "Indexed Folders"
2. Select a folder containing your documents
3. Wait for indexing to complete (progress bar shown)
4. Start chatting with your files!

### Asking Questions

Simply type natural language questions in the chat:

- *"What are the main themes in my notes?"*
- *"Summarize the key points from my resume"*
- *"What projects have I worked on?"*
- *"Find all mentions of machine learning"*

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ELECTRON (Desktop)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚            React + Tailwind CSS + Zustand              â”‚ â”‚
â”‚  â”‚   Sidebar | Chat | Sources Panel | Settings Modal      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â†• HTTP                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PYTHON BACKEND (FastAPI)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Indexer  â”‚  â”‚   RAG    â”‚  â”‚ Parsers  â”‚  â”‚ Vector Storeâ”‚ â”‚
â”‚  â”‚          â”‚  â”‚ Pipeline â”‚  â”‚ MD/PDF/  â”‚  â”‚  (ChromaDB) â”‚ â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚  Code    â”‚  â”‚             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â†• HTTP                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        OLLAMA                                â”‚
â”‚         Local LLM Inference + Embedding Generation           â”‚
â”‚              (llama3.2, nomic-embed-text, etc.)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
mnemora/
â”œâ”€â”€ electron/               # Electron main process
â”‚   â”œâ”€â”€ main.js             # Window management, IPC handlers
â”‚   â””â”€â”€ preload.js          # Secure bridge to renderer
â”œâ”€â”€ src/                    # React frontend
â”‚   â”œâ”€â”€ components/         # UI components
â”‚   â”‚   â”œâ”€â”€ Chat/           # ChatView, MessageBubble
â”‚   â”‚   â”œâ”€â”€ Sidebar/        # Folder management, status
â”‚   â”‚   â”œâ”€â”€ Sources/        # Citations panel
â”‚   â”‚   â”œâ”€â”€ Settings/       # Model selection, theme
â”‚   â”‚   â””â”€â”€ Setup/          # First-run setup wizard
â”‚   â”œâ”€â”€ stores/             # Zustand state management
â”‚   â””â”€â”€ index.css           # Tailwind + custom styles
â”œâ”€â”€ backend/                # Python FastAPI backend
â”‚   â”œâ”€â”€ api/                # REST endpoints
â”‚   â”œâ”€â”€ services/           # Core business logic
â”‚   â”‚   â”œâ”€â”€ indexer.py      # Document processing
â”‚   â”‚   â”œâ”€â”€ rag.py          # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ vector_store.py # ChromaDB wrapper
â”‚   â”‚   â””â”€â”€ ollama_client.py# Ollama API client
â”‚   â””â”€â”€ parsers/            # Document parsers
â”‚       â”œâ”€â”€ markdown_parser.py
â”‚       â”œâ”€â”€ pdf_parser.py
â”‚       â””â”€â”€ code_parser.py
â”œâ”€â”€ docs/                   # Documentation & screenshots
â”œâ”€â”€ SETUP.md                # Detailed setup guide
â”œâ”€â”€ CONTRIBUTING.md         # Contribution guidelines
â”œâ”€â”€ CODE_OF_CONDUCT.md      # Community standards
â””â”€â”€ SECURITY.md             # Security policy
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Ways to Contribute

- ğŸ› **Report Bugs** â€” Open an issue with reproduction steps
- ğŸ’¡ **Suggest Features** â€” Share your ideas for improvements
- ğŸ“ **Improve Docs** â€” Help make our documentation better
- ğŸ”§ **Submit PRs** â€” Fix bugs or add new features

### Development Setup

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and test thoroughly
4. Commit with descriptive messages: `git commit -m 'feat: add amazing feature'`
5. Push to your fork: `git push origin feature/amazing-feature`
6. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the **GNU General Public License v3.0** â€” see the [LICENSE](LICENSE) file for details.

This means you are free to:
- âœ… Use the software for any purpose
- âœ… Study and modify the source code
- âœ… Distribute copies
- âœ… Distribute modified versions

Under the condition that derivative works are also licensed under GPL-3.0.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) â€” For making local LLM inference accessible
- [ChromaDB](https://www.trychroma.com/) â€” For the excellent vector database
- [Electron](https://www.electronjs.org/) â€” For cross-platform desktop apps
- [Tailwind CSS](https://tailwindcss.com/) â€” For beautiful utility-first styling
- The open-source AI community for continuous inspiration

---

<div align="center">

**Made with â¤ï¸ for privacy-conscious knowledge workers**

[â¬† Back to Top](#-mnemora)

</div>
